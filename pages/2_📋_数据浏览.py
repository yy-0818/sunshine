import streamlit as st
import pandas as pd
from core.database import get_connection

st.set_page_config(page_title="æ•°æ®æµè§ˆ", layout="wide")
st.title("ğŸ“‹ æ•°æ®åº“æ•°æ®æµè§ˆ")

# è·å–æ‰€æœ‰è¡¨çš„æ•°æ®
def get_table_data(table_name):
    """è·å–æŒ‡å®šè¡¨çš„æ‰€æœ‰æ•°æ®"""
    with get_connection() as conn:
        try:
            df = pd.read_sql_query(f"SELECT * FROM {table_name} ORDER BY id", conn)
            return df
        except Exception as e:
            st.error(f"è¯»å–è¡¨ {table_name} æ—¶å‡ºé”™: {str(e)}")
            return pd.DataFrame()

# è·å–è¡¨è®°å½•æ•°
def get_table_count(table_name):
    """è·å–è¡¨çš„è®°å½•æ•°"""
    with get_connection() as conn:
        try:
            count = pd.read_sql_query(f"SELECT COUNT(*) as count FROM {table_name}", conn).iloc[0]['count']
            return count
        except Exception as e:
            st.error(f"è·å–è¡¨ {table_name} è®°å½•æ•°å¤±è´¥: {str(e)}")
            return 0

# è·å–æ‰€æœ‰è¡¨å
def get_table_names():
    """è·å–æ•°æ®åº“ä¸­çš„æ‰€æœ‰è¡¨å"""
    with get_connection() as conn:
        try:
            tables = pd.read_sql_query("""
                SELECT name FROM sqlite_master 
                WHERE type='table' AND name NOT LIKE 'sqlite_%'
                ORDER BY name
            """, conn)
            return tables['name'].tolist()
        except Exception as e:
            st.error(f"è·å–è¡¨åå¤±è´¥: {str(e)}")
            return []

# è·å–æ•°æ®åº“å¤§å°
def get_database_size():
    """è·å–æ•°æ®åº“å¤§å°"""
    with get_connection() as conn:
        try:
            db_info = pd.read_sql_query("""
                SELECT 
                    page_count * page_size as size_bytes,
                    (page_count * page_size) / 1024.0 as size_kb
                FROM (
                    SELECT 
                        page_count, 
                        page_size
                    FROM pragma_page_count(), pragma_page_size()
                )
            """, conn)
            if not db_info.empty:
                return db_info.iloc[0]['size_kb']
            return 0
        except Exception as e:
            st.error(f"è·å–æ•°æ®åº“å¤§å°å¤±è´¥: {str(e)}")
            return 0

# è·å–è¡¨çš„åˆ—ä¿¡æ¯
def get_table_columns(table_name):
    """è·å–è¡¨çš„åˆ—ä¿¡æ¯"""
    with get_connection() as conn:
        try:
            columns = pd.read_sql_query(f"PRAGMA table_info({table_name})", conn)
            return columns
        except Exception as e:
            st.error(f"è·å–è¡¨ {table_name} åˆ—ä¿¡æ¯å¤±è´¥: {str(e)}")
            return pd.DataFrame()

# ä¸»ç•Œé¢
st.subheader("ğŸ—ƒï¸ æ•°æ®åº“è¡¨é€‰æ‹©")

# è·å–æ‰€æœ‰è¡¨å
table_names = get_table_names()

if not table_names:
    st.warning("æ•°æ®åº“ä¸­æš‚æ— è¡¨")
else:
    # è¡¨é€‰æ‹©
    selected_table = st.selectbox("é€‰æ‹©è¦æŸ¥çœ‹çš„æ•°æ®è¡¨", table_names)
    
    if selected_table:
        # æ˜¾ç¤ºè¡¨ç»“æ„ä¿¡æ¯
        st.subheader(f"ğŸ“‹ {selected_table} è¡¨ç»“æ„")
        columns_info = get_table_columns(selected_table)
        if not columns_info.empty:
            st.dataframe(columns_info[['name', 'type', 'notnull', 'dflt_value']].rename(
                columns={'name': 'åˆ—å', 'type': 'æ•°æ®ç±»å‹', 'notnull': 'æ˜¯å¦éç©º', 'dflt_value': 'é»˜è®¤å€¼'}
            ), width="stretch")
        
        # è·å–è¡¨æ•°æ®
        with st.spinner(f"æ­£åœ¨åŠ è½½ {selected_table} è¡¨æ•°æ®..."):
            table_data = get_table_data(selected_table)
        
        if not table_data.empty:
            # è¡¨ä¿¡æ¯ç»Ÿè®¡
            st.subheader(f"ğŸ“Š {selected_table} è¡¨ä¿¡æ¯")
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("æ€»è®°å½•æ•°", len(table_data))
            with col2:
                st.metric("åˆ—æ•°", len(table_data.columns))
            with col3:
                st.metric("æ•°æ®å¤§å°", f"{table_data.memory_usage(deep=True).sum() / 1024:.1f} KB")
            with col4:
                # æ£€æŸ¥æ˜¯å¦æœ‰æ—¶é—´å­—æ®µ
                time_cols = [col for col in table_data.columns if 'date' in col.lower() or 'time' in col.lower()]
                if time_cols:
                    latest_date = table_data[time_cols[0]].max()
                    st.metric("æœ€æ–°è®°å½•", str(latest_date)[:10])
                else:
                    # æ£€æŸ¥æ˜¯å¦æœ‰idå­—æ®µ
                    if 'id' in table_data.columns:
                        st.metric("ä¸»é”®èŒƒå›´", f"{table_data['id'].min()} - {table_data['id'].max()}")
                    else:
                        st.metric("æ•°æ®çŠ¶æ€", "æ­£å¸¸")
            
            # æ•°æ®é¢„è§ˆ
            st.subheader("ğŸ‘€ æ•°æ®é¢„è§ˆ")
            
            # åˆ†é¡µæ§åˆ¶
            col1, col2, col3 = st.columns([.5, 4, .5])
            with col1:
                page_size = st.selectbox("æ¯é¡µæ˜¾ç¤ºè¡Œæ•°", [50, 100, 200, 500], index=0)
            with col2:
                st.write("")  # å ä½
            with col3:
                total_pages = max(1, (len(table_data) + page_size - 1) // page_size)
                page_number = st.number_input("", min_value=1, max_value=total_pages, value=1)
            
            # è®¡ç®—åˆ†é¡µ
            start_idx = (page_number - 1) * page_size
            end_idx = start_idx + page_size
            page_data = table_data.iloc[start_idx:end_idx]
            
            # æ˜¾ç¤ºæ•°æ®
            st.dataframe(page_data, width="stretch")
            
            # åˆ†é¡µä¿¡æ¯
            st.caption(f"ç¬¬ {page_number} / {total_pages} é¡µ` `ç¬¬ {start_idx + 1} - {min(end_idx, len(table_data))} è¡Œï¼Œå…± {len(table_data)} è¡Œ")
            
            # æ•°æ®ç»Ÿè®¡
            st.subheader("ğŸ“ˆ æ•°æ®ç»Ÿè®¡")
            
            tab1, tab2, tab3 = st.tabs(["åˆ—ä¿¡æ¯", "æ•°æ®ç±»å‹", "æ•°å€¼ç»Ÿè®¡"])
            
            with tab1:
                # åˆ—ä¿¡æ¯
                col_info = []
                for col in table_data.columns:
                    col_info.append({
                        'åˆ—å': col,
                        'éç©ºå€¼æ•°': table_data[col].count(),
                        'ç©ºå€¼æ•°': table_data[col].isnull().sum(),
                        'ç©ºå€¼æ¯”ä¾‹': f"{(table_data[col].isnull().sum() / len(table_data) * 100):.1f}%",
                        'å”¯ä¸€å€¼æ•°': table_data[col].nunique()
                    })
                col_info_df = pd.DataFrame(col_info)
                st.dataframe(col_info_df, width="stretch")
            
            with tab2:
                # æ•°æ®ç±»å‹
                dtype_info = []
                for col in table_data.columns:
                    dtype = table_data[col].dtype
                    sample_value = table_data[col].iloc[0] if not table_data[col].empty else None
                    dtype_info.append({
                        'åˆ—å': col,
                        'æ•°æ®ç±»å‹': str(dtype),
                        'ç¤ºä¾‹å€¼': str(sample_value)[:50] if sample_value is not None else 'None'
                    })
                dtype_df = pd.DataFrame(dtype_info)
                st.dataframe(dtype_df, width="stretch")
            
            with tab3:
                # æ•°å€¼åˆ—ç»Ÿè®¡
                numeric_cols = table_data.select_dtypes(include=['number']).columns
                if len(numeric_cols) > 0:
                    numeric_stats = table_data[numeric_cols].describe()
                    st.dataframe(numeric_stats, width="stretch")
                else:
                    st.info("è¯¥è¡¨æ²¡æœ‰æ•°å€¼åˆ—")
            
            # æ•°æ®å¯¼å‡º
            st.subheader("ğŸ’¾ æ•°æ®å¯¼å‡º")
            
            col1, col2 = st.columns(2)
            
            with col1:
                # å¯¼å‡ºå½“å‰é¡µ
                page_csv = page_data.to_csv(index=False).encode('utf-8')
                st.download_button(
                    "ğŸ“¥ å¯¼å‡ºå½“å‰é¡µ(CSV)",
                    page_csv,
                    f"{selected_table}_page_{page_number}.csv",
                    "text/csv",
                    width="stretch"
                )
            
            with col2:
                # å¯¼å‡ºæ•´ä¸ªè¡¨
                full_csv = table_data.to_csv(index=False).encode('utf-8')
                st.download_button(
                    "ğŸ“¥ å¯¼å‡ºæ•´ä¸ªè¡¨(CSV)",
                    full_csv,
                    f"{selected_table}_full.csv",
                    "text/csv",
                    width="stretch"
                )
            
            # å¿«é€ŸæŸ¥è¯¢
            st.subheader("ğŸ” å¿«é€ŸæŸ¥è¯¢")
            
            query_col1, query_col2 = st.columns([3, 1])
            with query_col1:
                search_term = st.text_input("æœç´¢å…³é”®è¯", placeholder="åœ¨æ‰€æœ‰åˆ—ä¸­æœç´¢...")
            with query_col2:
                st.write("")  # å ä½
                st.write("")  # å ä½
                search_clicked = st.button("æœç´¢", width="stretch")
            
            if search_clicked and search_term:
                # åœ¨æ‰€æœ‰åˆ—ä¸­æœç´¢
                search_results = table_data.copy()
                mask = pd.Series([False] * len(search_results))
                
                for col in search_results.columns:
                    if search_results[col].dtype == 'object':
                        col_mask = search_results[col].astype(str).str.contains(
                            search_term, case=False, na=False
                        )
                        mask = mask | col_mask
                
                search_results = search_results[mask]
                
                if not search_results.empty:
                    st.success(f"æ‰¾åˆ° {len(search_results)} æ¡åŒ¹é…è®°å½•")
                    st.dataframe(search_results, width="stretch")
                    
                    # å¯¼å‡ºæœç´¢ç»“æœ
                    search_csv = search_results.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        "ğŸ“¥ å¯¼å‡ºæœç´¢ç»“æœ(CSV)",
                        search_csv,
                        f"{selected_table}_search_results.csv",
                        "text/csv",
                        width="stretch"
                    )
                else:
                    st.warning("æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„è®°å½•")
        
        else:
            st.warning(f"è¡¨ {selected_table} ä¸­æ²¡æœ‰æ•°æ®")
    
    # æ•°æ®åº“æ¦‚è§ˆ
    st.subheader("ğŸ—„ï¸ æ•°æ®åº“æ¦‚è§ˆ")
    
    overview_col1, overview_col2 = st.columns(2)
    
    with overview_col1:
        st.write("**æ‰€æœ‰æ•°æ®è¡¨:**")
        total_records = 0
        for table in table_names:
            count = get_table_count(table)
            total_records += count
            st.write(f"- {table}: {count} æ¡è®°å½•")
    
    with overview_col2:
        # æ•°æ®åº“å¤§å°ä¿¡æ¯
        db_size_kb = get_database_size()
        st.write("**æ•°æ®åº“ä¿¡æ¯:**")
        st.write(f"- æ€»å¤§å°: {db_size_kb:.1f} KB")
        st.write(f"- è¡¨æ•°é‡: {len(table_names)}")
        st.write(f"- æ€»è®°å½•æ•°: {total_records}")

# ä½¿ç”¨è¯´æ˜
with st.expander("ğŸ“š ä½¿ç”¨è¯´æ˜", expanded=False):
    st.markdown("""
    ### æ•°æ®æµè§ˆåŠŸèƒ½è¯´æ˜
    
    **ä¸»è¦åŠŸèƒ½**
    - ğŸ“Š æŸ¥çœ‹æ•°æ®åº“ä¸­æ‰€æœ‰è¡¨çš„æ•°æ®
    - ğŸ” æ”¯æŒåˆ†é¡µæµè§ˆå’Œæœç´¢
    - ğŸ“ˆ æä¾›è¯¦ç»†çš„æ•°æ®ç»Ÿè®¡ä¿¡æ¯
    - ğŸ’¾ æ”¯æŒæ•°æ®å¯¼å‡º
    
    **è¡¨è¯´æ˜**
    - **customers**: å®¢æˆ·ä¿¡æ¯è¡¨
    - **sales_records**: é”€å”®è®°å½•è¡¨  
    - **price_change_history**: ä»·æ ¼å˜æ›´å†å²è¡¨
    
    **ä½¿ç”¨æŠ€å·§**
    - ä½¿ç”¨åˆ†é¡µåŠŸèƒ½æµè§ˆå¤§é‡æ•°æ®
    - åˆ©ç”¨æœç´¢åŠŸèƒ½å¿«é€Ÿå®šä½æ•°æ®
    - æŸ¥çœ‹æ•°æ®ç»Ÿè®¡äº†è§£æ•°æ®è´¨é‡
    - å¯¼å‡ºæ•°æ®ç”¨äºè¿›ä¸€æ­¥åˆ†æ
    
    **æ³¨æ„äº‹é¡¹**
    - å¤§æ•°æ®è¡¨å»ºè®®ä½¿ç”¨åˆ†é¡µåŠŸèƒ½
    - å¯¼å‡ºæ•´ä¸ªè¡¨æ—¶è¯·æ³¨æ„æ•°æ®é‡
    - æœç´¢åŠŸèƒ½åœ¨æ‰€æœ‰æ–‡æœ¬åˆ—ä¸­è¿›è¡Œ
    
    ### è¡¨ç»“æ„è¯´æ˜
    
    **customers è¡¨**
    - `id`: ä¸»é”®ï¼Œè‡ªå¢é•¿
    - `customer_name`: å®¢æˆ·åç§° (å¿…éœ€)
    - `finance_id`: è´¢åŠ¡ç¼–å· (å¿…éœ€)
    - `sub_customer_name`: å­å®¢æˆ·åç§° (å¯é€‰)
    - `region`: åŒºåŸŸä¿¡æ¯ (å¯é€‰)
    - `contact_person`: è”ç³»äºº (å¯é€‰)
    - `phone`: è”ç³»ç”µè¯ (å¯é€‰)
    - `created_date`: åˆ›å»ºæ—¶é—´
    - `updated_date`: æ›´æ–°æ—¶é—´
    - `is_active`: æ˜¯å¦æ´»è·ƒ
    
    **sales_records è¡¨**
    - `id`: ä¸»é”®ï¼Œè‡ªå¢é•¿
    - `customer_name`: å®¢æˆ·åç§° (å¿…éœ€)
    - `finance_id`: è´¢åŠ¡ç¼–å· (å¿…éœ€)
    - `sub_customer_name`: å­å®¢æˆ·åç§° (å¯é€‰)
    - `year`: äº¤æ˜“å¹´ä»½ (å¿…éœ€)
    - `month`: äº¤æ˜“æœˆä»½ (å¿…éœ€)
    - `day`: äº¤æ˜“æ—¥æœŸ (å¿…éœ€)
    - `color`: äº§å“é¢œè‰² (å¿…éœ€)
    - `grade`: äº§å“ç­‰çº§ (å¯é€‰)
    - `quantity`: é”€å”®æ•°é‡ (å¯é€‰)
    - `unit_price`: äº§å“å•ä»· (å¯é€‰)
    - `amount`: é”€å”®é‡‘é¢ (å¯é€‰)
    - `ticket_number`: ç¥¨æ®å·ç  (å¯é€‰)
    - `remark`: äº¤æ˜“å¤‡æ³¨ (å¯é€‰)
    - `production_line`: ç”Ÿäº§çº¿ä¿¡æ¯ (å¯é€‰)
    - `record_date`: è®°å½•æ—¥æœŸ
    - `created_date`: åˆ›å»ºæ—¶é—´
    - `updated_date`: æ›´æ–°æ—¶é—´
    
    **price_change_history è¡¨**
    - `id`: ä¸»é”®ï¼Œè‡ªå¢é•¿
    - `sales_record_id`: å…³è”çš„é”€å”®è®°å½•ID
    - `old_price`: å˜æ›´å‰çš„ä»·æ ¼
    - `new_price`: å˜æ›´åçš„ä»·æ ¼
    - `change_date`: ä»·æ ¼å˜æ›´æ—¶é—´
    - `changed_by`: å˜æ›´æ“ä½œäºº
    - `change_reason`: å˜æ›´åŸå› 
    """)