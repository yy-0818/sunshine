import pandas as pd
import warnings
import os
from openpyxl import load_workbook
from typing import Tuple, Dict, Any

import os
import pandas as pd
import warnings
from openpyxl import load_workbook
from typing import Tuple, Dict, Any

def validate_excel_structure(file_path: str) -> Tuple[bool, str]:
    """éªŒè¯Excelæ–‡ä»¶ç»“æ„å¹¶è¿›è¡Œè¡¨å¤´æ˜ å°„"""
    try:
        # ç›´æ¥ä½¿ç”¨pandasè¯»å–ï¼Œè®©å®ƒè‡ªåŠ¨é€‰æ‹©å¼•æ“
        try:
            df = pd.read_excel(file_path, engine=None, nrows=1)
        except Exception as e:
            # å¦‚æœè‡ªåŠ¨é€‰æ‹©å¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨é€‰æ‹©
            file_ext = os.path.splitext(file_path)[1].lower()
            if file_ext == '.xls':
                # æ£€æŸ¥æ˜¯å¦å®‰è£…äº†xlrd
                try:
                    import xlrd
                    df = pd.read_excel(file_path, engine='xlrd', nrows=1)
                except ImportError:
                    return False, "éœ€è¦å®‰è£…xlrdåº“æ¥å¤„ç†.xlsæ–‡ä»¶ã€‚è¯·è¿è¡Œ: pip install xlrd"
            else:
                # å°è¯•openpyxl
                df = pd.read_excel(file_path, engine='openpyxl', nrows=1)
        
        # è·å–è¡¨å¤´
        headers = [str(col).strip() for col in df.columns]
        
        # åº”ç”¨è¡¨å¤´æ˜ å°„
        mapped_headers = []
        header_mapping = {
            'å¤‡æ³¨ï¼ˆå°å®¢æˆ·åç§°ï¼‰': 'å­å®¢æˆ·åç§°',
            'ç¥¨ å·': 'ç¥¨å·',
            'å“ç‰Œ': 'å¤‡æ³¨'
        }
        
        for header in headers:
            header_no_space = header.replace(' ', '')
            mapped_header = header
            for original, standard in header_mapping.items():
                if header_no_space == original.replace(' ', ''):
                    mapped_header = standard
                    break
            mapped_headers.append(mapped_header)
        
        # å¿…éœ€çš„è¡¨å¤´ï¼ˆæ˜ å°„åçš„æ ‡å‡†è¡¨å¤´ï¼‰
        required_headers = ['å®¢æˆ·åç§°', 'ç¼–å·', 'å­å®¢æˆ·åç§°', 'å¹´', 'æœˆ', 'æ—¥', 'æ”¶æ¬¾é‡‘é¢', 'é¢œè‰²', 'ç­‰çº§', 'æ•°é‡', 'å•ä»·', 'é‡‘é¢', 'ä½™é¢', 'ç¥¨å·', 'å¤‡æ³¨', 'ç”Ÿäº§çº¿']
        
        # å»é™¤ç©ºæ ¼åçš„è¡¨å¤´ç”¨äºåŒ¹é…
        mapped_headers_no_space = [h.replace(' ', '') for h in mapped_headers]
        required_headers_no_space = [h.replace(' ', '') for h in required_headers]
        
        missing_headers = []
        for req_header, req_header_ns in zip(required_headers, required_headers_no_space):
            if req_header_ns not in mapped_headers_no_space:
                missing_headers.append(req_header)
        
        if missing_headers:
            return False, f"ç¼ºå°‘å¿…è¦çš„è¡¨å¤´: {missing_headers}"
        
        return True, "æ–‡ä»¶ç»“æ„æ­£ç¡®"
        
    except Exception as e:
        return False, f"æ–‡ä»¶æ£€æŸ¥å¤±è´¥: {str(e)}"

def preview_excel_data(file_path: str, nrows: int = 5) -> Tuple[bool, pd.DataFrame]:
    """é¢„è§ˆExcelæ•°æ®ï¼ˆåº”ç”¨è¡¨å¤´æ˜ å°„ï¼‰ï¼Œæ”¯æŒ.xlså’Œ.xlsxæ ¼å¼"""
    try:
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            
            # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©å¼•æ“
            file_ext = os.path.splitext(file_path)[1].lower()
            if file_ext == '.xls':
                engine = 'xlrd'
            else:
                engine = 'openpyxl'
            
            # å…ˆè¯»å–åŸå§‹æ•°æ®
            df = pd.read_excel(file_path, engine=engine, nrows=nrows)
            
            # åº”ç”¨è¡¨å¤´æ˜ å°„
            df = apply_header_mapping(df)
            
        return True, df
    except Exception as e:
        return False, f"æ— æ³•è¯»å–æ–‡ä»¶: {str(e)}"

def apply_header_mapping(df: pd.DataFrame) -> pd.DataFrame:
    """åº”ç”¨è¡¨å¤´æ˜ å°„åˆ°DataFrame"""
    # å®šä¹‰è¡¨å¤´æ˜ å°„å…³ç³»
    header_mapping = {
        'å¤‡æ³¨ï¼ˆå°å®¢æˆ·åç§°ï¼‰': 'å­å®¢æˆ·åç§°',
        'ç¥¨ å·': 'ç¥¨å·',
        'å“ç‰Œ': 'å¤‡æ³¨'
    }
    
    # åˆ›å»ºæ–°çš„åˆ—ååˆ—è¡¨
    new_columns = []
    for col in df.columns:
        original_col = str(col).strip()
        # å»é™¤ç©ºæ ¼è¿›è¡ŒåŒ¹é…
        original_col_no_space = original_col.replace(' ', '')
        mapped_col = original_col
        
        # æ£€æŸ¥æ˜ å°„å…³ç³»
        for original, standard in header_mapping.items():
            if original_col_no_space == original.replace(' ', ''):
                mapped_col = standard
                break
        
        new_columns.append(mapped_col)
    
    # åº”ç”¨æ–°çš„åˆ—å
    df_mapped = df.copy()
    df_mapped.columns = new_columns
    
    return df_mapped

def get_excel_file_info(file_path: str) -> Dict[str, Any]:
    """è·å–Excelæ–‡ä»¶çš„è¯¦ç»†ä¿¡æ¯ï¼ˆåº”ç”¨è¡¨å¤´æ˜ å°„ï¼‰ï¼Œæ”¯æŒ.xlså’Œ.xlsxæ ¼å¼"""
    try:
        file_ext = os.path.splitext(file_path)[1].lower()
        
        if file_ext == '.xls':
            # ä½¿ç”¨xlrdè¯»å–.xlsæ–‡ä»¶
            import xlrd
            wb = xlrd.open_workbook(file_path, on_demand=True)
            sheet = wb.sheet_by_index(0)
            
            # è·å–åŸå§‹è¡¨å¤´
            original_headers = []
            for col_idx in range(sheet.ncols):
                cell_value = sheet.cell_value(0, col_idx)
                if cell_value is not None:
                    original_headers.append(str(cell_value).strip())
            
            # ç»Ÿè®¡è¡Œæ•°ï¼ˆä¸åŒ…æ‹¬è¡¨å¤´ï¼‰
            row_count = 0
            for row_idx in range(1, min(100000, sheet.nrows)):
                if sheet.cell_value(row_idx, 0) is not None:
                    row_count += 1
            
            wb.release_resources()
            
        elif file_ext in ['.xlsx', '.xlsm']:
            # ä½¿ç”¨openpyxlè¯»å–.xlsxæ–‡ä»¶
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                wb = load_workbook(file_path, data_only=True, read_only=True)
                sheet = wb.active
                
                # è·å–åŸå§‹è¡¨å¤´
                original_headers = []
                for cell in sheet[1]:
                    if cell.value is not None:
                        original_headers.append(str(cell.value).strip())
                
                # ç»Ÿè®¡è¡Œæ•°ï¼ˆä¸åŒ…æ‹¬è¡¨å¤´ï¼‰
                row_count = 0
                for row_idx, row in enumerate(sheet.iter_rows(min_row=2, max_row=100000), 2):
                    if row[0].value is not None:
                        row_count += 1
                    else:
                        break
                
                wb.close()
        else:
            return {"error": f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}"}
        
        # åº”ç”¨è¡¨å¤´æ˜ å°„
        mapped_headers = []
        header_mapping = {
            'å¤‡æ³¨ï¼ˆå°å®¢æˆ·åç§°ï¼‰': 'å­å®¢æˆ·åç§°',
            'ç¥¨ å·': 'ç¥¨å·',
            'å“ç‰Œ': 'å¤‡æ³¨'
        }
        
        for header in original_headers:
            header_no_space = header.replace(' ', '')
            mapped_header = header
            for original, standard in header_mapping.items():
                if header_no_space == original.replace(' ', ''):
                    mapped_header = standard
                    break
            mapped_headers.append(mapped_header)
        
        # è¯»å–æ•°æ®å¹¶åº”ç”¨è¡¨å¤´æ˜ å°„
        engine = 'xlrd' if file_ext == '.xls' else 'openpyxl'
        df = pd.read_excel(file_path, engine=engine, nrows=1000)
        df = apply_header_mapping(df)
        
        # åˆ›å»ºå»é™¤ç©ºæ ¼åçš„åˆ—åæ˜ å°„
        column_mapping = {}
        for col in df.columns:
            col_no_space = col.replace(' ', '')
            column_mapping[col_no_space] = col
        
        info = {
            "original_headers": original_headers,
            "mapped_headers": mapped_headers,
            "headers": mapped_headers,  # ä¿æŒå…¼å®¹æ€§
            "row_count": row_count,
            "column_count": len(mapped_headers),
            "required_headers_present": True,
            "sample_data_available": len(df) > 0 if not df.empty else False,
            "column_mapping": column_mapping
        }
        
        # å¦‚æœæ•°æ®ä¸ä¸ºç©ºï¼Œæ·»åŠ æ›´å¤šç»Ÿè®¡ä¿¡æ¯
        if not df.empty:
            # ä½¿ç”¨æ˜ å°„åçš„åˆ—å
            customer_col = 'å®¢æˆ·åç§°'
            product_col = 'äº§å“åç§°' if 'äº§å“åç§°' in df.columns else None
            color_col = 'é¢œè‰²'
            quantity_col = 'æ•°é‡'
            price_col = 'å•ä»·'
            amount_col = 'é‡‘é¢'
            
            info.update({
                "customer_count": df[customer_col].nunique() if customer_col in df.columns else 0,
                "product_count": df[product_col].nunique() if product_col and product_col in df.columns else 0,
                "color_count": df[color_col].nunique() if color_col in df.columns else 0,
                "has_numeric_data": any(col in df.columns for col in [quantity_col, price_col, amount_col])
            })
        
        return info
        
    except Exception as e:
        return {"error": f"è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {str(e)}"}

def get_import_strategy_description(strategy: str) -> Dict[str, Any]:
    """è·å–å¯¼å…¥ç­–ç•¥çš„è¯¦ç»†è¯´æ˜"""
    descriptions = {
        "update": {
            "name": "æ™ºèƒ½æ›´æ–°",
            "description": "æ›´æ–°é‡å¤æ•°æ®ï¼Œæ·»åŠ æ–°æ•°æ®ï¼Œä¿æŒæ•°æ®åŒæ­¥",
            "icon": "ğŸ“",
            "recommended": True,
            "details": [
                "âœ… æ›´æ–°é‡å¤çš„é”€å”®è®°å½•",
                "âœ… æ·»åŠ æ–°çš„é”€å”®è®°å½•",  
                "âœ… ä¿æŒå®¢æˆ·ä¿¡æ¯åŒæ­¥æ›´æ–°",
                "ğŸ’¡ **é€‚ç”¨åœºæ™¯**: æ—¥å¸¸æ•°æ®æ›´æ–°ã€ä¿®æ­£é”™è¯¯æ•°æ®"
            ]
        },
        "append": {
            "name": "ä»…æ–°å¢", 
            "description": "åªå¯¼å…¥ä¸å­˜åœ¨çš„æ–°æ•°æ®ï¼Œä¸ä¿®æ”¹å·²æœ‰è®°å½•",
            "icon": "â•",
            "recommended": False,
            "details": [
                "âœ… åªå¯¼å…¥ä¸å­˜åœ¨çš„æ–°æ•°æ®",
                "âŒ ä¸ä¿®æ”¹ä»»ä½•å·²æœ‰è®°å½•", 
                "ğŸ’¡ **é€‚ç”¨åœºæ™¯**: è¡¥å……å†å²æ•°æ®ã€é¿å…æ•°æ®å†²çª"
            ]
        },
        "replace": {
            "name": "å®Œå…¨æ›¿æ¢",
            "description": "æ¸…ç©ºæ‰€æœ‰æ•°æ®åé‡æ–°å¯¼å…¥å®Œæ•´æ•°æ®é›†", 
            "icon": "ğŸ”„",
            "recommended": False,
            "details": [
                "âš ï¸ æ¸…ç©ºæ‰€æœ‰ç°æœ‰æ•°æ®",
                "âš ï¸ é‡æ–°å¯¼å…¥å®Œæ•´æ•°æ®é›†",
                "ğŸ’¡ **é€‚ç”¨åœºæ™¯**: æ•°æ®é‡æ„ã€é‡å¤§ç»“æ„è°ƒæ•´"
            ]
        }
    }
    return descriptions.get(strategy, descriptions["update"])

def validate_data_quality(df: pd.DataFrame) -> Dict[str, Any]:
    """éªŒè¯æ•°æ®è´¨é‡ï¼ˆä½¿ç”¨æ˜ å°„åçš„åˆ—åï¼‰"""
    issues = []
    warnings = []
    
    # åº”ç”¨è¡¨å¤´æ˜ å°„
    df_mapped = apply_header_mapping(df)
    
    # åˆ›å»ºå»é™¤ç©ºæ ¼åçš„åˆ—åæ˜ å°„
    column_mapping = {}
    for col in df_mapped.columns:
        col_no_space = col.replace(' ', '')
        column_mapping[col_no_space] = col
    
    # æ£€æŸ¥å¿…éœ€å­—æ®µçš„ç©ºå€¼
    required_fields = ['å®¢æˆ·åç§°', 'ç¼–å·']
    for field in required_fields:
        actual_col = column_mapping.get(field, field)
        if actual_col in df_mapped.columns:
            null_count = df_mapped[actual_col].isnull().sum()
            if null_count > 0:
                issues.append(f"å­—æ®µ '{actual_col}' æœ‰ {null_count} ä¸ªç©ºå€¼")
    
    # æ£€æŸ¥æ•°å€¼å­—æ®µçš„æœ‰æ•ˆæ€§
    numeric_fields = ['æ•°é‡', 'å•ä»·', 'é‡‘é¢', 'æ”¶æ¬¾é‡‘é¢']
    for field in numeric_fields:
        actual_col = column_mapping.get(field, field)
        if actual_col in df_mapped.columns:
            # æ£€æŸ¥å¼‚å¸¸å¤§å€¼ï¼ˆå‡è®¾å¤§äº100ä¸‡ä¸ºå¼‚å¸¸ï¼‰
            large_value_count = (df_mapped[actual_col] > 1000000).sum()
            if large_value_count > 0:
                warnings.append(f"å­—æ®µ '{actual_col}' æœ‰ {large_value_count} ä¸ªå¼‚å¸¸å¤§å€¼")
    
    # æ£€æŸ¥æ—¥æœŸå­—æ®µçš„æœ‰æ•ˆæ€§
    date_fields = ['å¹´', 'æœˆ', 'æ—¥']
    for field in date_fields:
        actual_col = column_mapping.get(field, field)
        if actual_col in df_mapped.columns:
            invalid_count = df_mapped[actual_col].isnull().sum()
            if invalid_count > 0:
                warnings.append(f"å­—æ®µ '{actual_col}' æœ‰ {invalid_count} ä¸ªæ— æ•ˆå€¼")
    
    return {
        "has_issues": len(issues) > 0,
        "has_warnings": len(warnings) > 0,
        "issues": issues,
        "warnings": warnings,
        "total_records": len(df_mapped),
        "valid_records": len(df_mapped) - len(issues)
    }

def get_recommended_strategy(file_info: Dict[str, Any], db_status: Dict[str, Any]) -> str:
    """æ ¹æ®æ–‡ä»¶ä¿¡æ¯å’Œæ•°æ®åº“çŠ¶æ€æ¨èå¯¼å…¥ç­–ç•¥"""
    
    # å¦‚æœæ•°æ®åº“ä¸ºç©ºï¼Œæ¨èæ›¿æ¢æ¨¡å¼
    if db_status.get('sales_records_count', 0) == 0:
        return "replace"
    
    # å¦‚æœæ–‡ä»¶åŒ…å«å¤§é‡æ•°æ®ä¸”æ•°æ®åº“å·²æœ‰æ•°æ®ï¼Œæ¨èæ›´æ–°æ¨¡å¼
    if file_info.get('row_count', 0) > 1000 and db_status.get('sales_records_count', 0) > 0:
        return "update"
    
    # å¦‚æœæ–‡ä»¶æ•°æ®é‡è¾ƒå°ï¼Œæ¨èè¿½åŠ æ¨¡å¼
    if file_info.get('row_count', 0) < 100:
        return "append"
    
    # é»˜è®¤æ¨èæ›´æ–°æ¨¡å¼
    return "update"

# æ–°å¢å‡½æ•°ï¼šæ ‡å‡†åŒ–åˆ—åï¼ˆå»é™¤ç©ºæ ¼ï¼‰
def standardize_column_names(df: pd.DataFrame) -> pd.DataFrame:
    """æ ‡å‡†åŒ–DataFrameçš„åˆ—åï¼Œå»é™¤ç©ºæ ¼"""
    df_standardized = df.copy()
    df_standardized.columns = [col.replace(' ', '') for col in df_standardized.columns]
    return df_standardized

# æ–°å¢å‡½æ•°ï¼šè·å–åŸå§‹åˆ—ååˆ°æ ‡å‡†åˆ—åçš„æ˜ å°„
def get_column_mapping(headers: list) -> Dict[str, str]:
    """è·å–åŸå§‹åˆ—ååˆ°æ ‡å‡†åˆ—åï¼ˆå»é™¤ç©ºæ ¼ï¼‰çš„æ˜ å°„"""
    mapping = {}
    for header in headers:
        standard_header = header.replace(' ', '')
        mapping[standard_header] = header
    return mapping